{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJCLHzIX76zh2kgz9ueFj/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megumihoshino/ML-intermediate_new/blob/main/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-vvkAXu6zMY"
      },
      "outputs": [],
      "source": [
        "#EKSTRASI FITUR\n",
        "\n",
        "'''\n",
        "EKSTRAKSI FITUR adalah proses memyaring informasi mjd btk yg lbh\n",
        "ringkas dan bermakna bagi model kita.\n",
        "\n",
        "tujuannya adlh utk mengubah teks mjd btk yg dpt dipahami oleh algoritma\n",
        "ML, yaitu numerik. dg ekstraksi fitur, kita dpt identifikasi pola, tema\n",
        "atau sentimen utkn membangun model prediksi atau klasifikasi yg cerdas.\n",
        "\n",
        "bbrp teknik umum yg digunakan utk ekstraksi fitur pd teks:\n",
        "- word embedding\n",
        "- term frequency-inverse document frequency (tf-idf)\n",
        "- bag of words (bog)\n",
        "- n-gram\n",
        "- pos tagging (part of speech tagging)\n",
        "- entity recognition\n",
        "- pola atau pola kata (pattern matching)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. WORD EMBEDDING\n",
        "'''\n",
        "teknik dlm NLP utk MEREPRESENTASIKAN DISTRIBUSI KATA2 DI RUANG VEKTOR.\n",
        "setiap kata direpresentasikan sbg VEKTOR NUMBERIK BERDIMENSI RENDAH.\n",
        "\n",
        "7an utama dari teknik ini adlh menangkap hubungan semantik dan sintaktis\n",
        "antarkata dlm teks. kata2 yg memiliki makna atau konteks mirip akn\n",
        "cenderung direpresentasikan dg vektor sereupa atau mendekati satu sm\n",
        "lain dlm ruang embedding. cth hub semantik yg dpt ditangkap oleh word\n",
        "embedding termsk sinonim, antonim, hub hierarkis, dan hub konseptual\n",
        "lainnya.\n",
        "\n",
        "ada bbrp teknik word embedding yg populer digunakan dlm nlp:\n",
        "1. word2vec\n",
        "  - skipgram: model word2vec skip-gram melatih NN utk memprediksi kata\n",
        "  konteks berdasarkan kata target dlm suatu kalimat. (lbh baik utk dataset kecil)\n",
        "  - CBOW: kebalikan dari skip-gram. memprediksi kata target berdasarkan\n",
        "  kata-kata konteks. (lbh baik dan cpt utk dataset besar)\n",
        "\n",
        "2. glove (global vectors for word representastion)\n",
        "  metode word embedding utk menghasilkan vektor representasu kata2 bedsrkan\n",
        "  statistik dr matriks frekuensi kemunculan kata dlm teks (co-occurence matrix)\n",
        "\n",
        "  tujuan glove adalah memahami hub antar kata berdsrkan sebrp sering\n",
        "  kata tsb2 muncul bersm2 dlm korpus teks.\n",
        "\n",
        "3. FastText\n",
        "ekstensi dari word2vec yg dikembangkan oleh Facebook AI Research (FAIR)\n",
        "keunggulan dari fasttext adlh kemampuan utk memeperhitungkan struktur\n",
        "internal kata (subword information) dlm pembtkan representasi vektor kata, membuat\n",
        "FastText lbh efektif ketika menangani kata2 yg jarang atau tdk ditemukan dlm\n",
        "kosakata (out-of-vocabulary words).'''\n",
        "\n",
        "#2. TERM FREQUENCY-INVERSE DOCUMENT FREQUENCY (TF-IDF)\n",
        "'''\n",
        "digunakan utk mengeavluasi sbrp penting sebuah kata pd suatu dokumen\n",
        "dlm konteks korpus atau kumpulan doc yg lbh besar. 7annya adlh utk\n",
        "menimbang kata2 shg kata2 yg sering muncul dlm satu dokumen, ttpi jarang\n",
        "muncul di dokumen lain, dianggap lbh penting dan memiliki bobot yg lbh tinggi.\n",
        "\n",
        "--> term frequency\n",
        "mengukur sbrp sering sebuah kata muncul dlm sebuah dokumen.\n",
        "TF (t,d) = jml kata t dlm d/total kata dlm d\n",
        "\n",
        "artinya:\n",
        "- jml kata t dlm d adlh jml kemunculan kata t dlm dokumen d\n",
        "- total kata dlm d adlh jml kata dlm dokumen d\n",
        "\n",
        "--> inverse document frequency (idf)\n",
        "digunakan utk mengukur sebrp jarang kata tertentu muncul di seluruh doc\n",
        "dlm korpus.\n",
        "IDF(t, D) = log (total dokumen dlm D/jml dokumen yg mengandung t)\n",
        "\n",
        "artinya:\n",
        "- total dokumen dlm D adlh jml dokumen dlm korpus D\n",
        "- jml dokumen yg mengandung t adlh jml dokumen dlm korpus yg mengandung kata t\n",
        "\n",
        "-----------------------------------\n",
        "TF-IDF(t,d,D) = TF(t,d) * IDF(t,D) |\n",
        "-----------------------------------\n",
        "'''\n"
      ],
      "metadata": {
        "id": "3WSgYgkPShZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#an example code from copilot, TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#example doc\n",
        "documents = [\"Saya suka belajar machine learning\",\n",
        "             \"Machine learning sangat menarik\",\n",
        "             \"Saya suka belajar Python\",\n",
        "             \"Python sangat kuat untuk machine learning\"]\n",
        "\n",
        "#inisialisasi TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "#fit dan transformasi dokumen\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "#menampilkan hasil\n",
        "print(\"Fitur (kata-kata): \", vectorizer.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix: \\n\", tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbpKnf8zeX9N",
        "outputId": "386069c4-86a7-44fc-bc89-42985c001355"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitur (kata-kata):  ['belajar' 'kuat' 'learning' 'machine' 'menarik' 'python' 'sangat' 'saya'\n",
            " 'suka' 'untuk']\n",
            "TF-IDF Matrix: \n",
            " [[0.48163503 0.         0.38992506 0.38992506 0.         0.\n",
            "  0.         0.48163503 0.48163503 0.        ]\n",
            " [0.         0.         0.40892206 0.40892206 0.64065543 0.\n",
            "  0.5051001  0.         0.         0.        ]\n",
            " [0.5        0.         0.         0.         0.         0.5\n",
            "  0.         0.5        0.5        0.        ]\n",
            " [0.         0.49641358 0.31685436 0.31685436 0.         0.39137817\n",
            "  0.39137817 0.         0.         0.49641358]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#another example\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#example doc\n",
        "documents = [\"Saya suka makan nasi goreng\",\n",
        "             \"Nasi goreng adalah makanan favorit saya\",\n",
        "             \"Saya sering makan nasi goreng di pagi hari\"]\n",
        "\n",
        "#inisialisasi TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "#fit dan transformasi dokumen\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "#menampilkan hasil\n",
        "print(\"Fitur (kata-kata): \", vectorizer.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix: \\n\", tfidf_matrix.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ8pAZ4HfHhB",
        "outputId": "765d9392-5aed-4922-8927-03e55a3f3523"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitur (kata-kata):  ['adalah' 'di' 'favorit' 'goreng' 'hari' 'makan' 'makanan' 'nasi' 'pagi'\n",
            " 'saya' 'sering' 'suka']\n",
            "TF-IDF Matrix: \n",
            " [[0.         0.         0.         0.3645444  0.         0.46941728\n",
            "  0.         0.3645444  0.         0.3645444  0.         0.61722732]\n",
            " [0.49711994 0.         0.49711994 0.29360705 0.         0.\n",
            "  0.49711994 0.29360705 0.         0.29360705 0.         0.        ]\n",
            " [0.         0.42164146 0.         0.24902824 0.42164146 0.3206692\n",
            "  0.         0.24902824 0.42164146 0.24902824 0.42164146 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BAG OF WORDS (BoW)\n",
        "\n",
        "'''\n",
        "pendekatan sederhana dlm pemrosesan teks yg digunakan utk mewakili\n",
        "teks sbg kumpulan kata2 terurut tnp memperhatikan tata urutan atau\n",
        "struktur kalimat. langkah2:\n",
        "- tokenisasi:teks dibagi mjd unit2 kecil, sprt kata2 atau n-gram\n",
        "- membuat vocab: kata unik dipetakan dlm teks pd indeks numerik.\n",
        "- representasi vektor: setiap elemen vektor mengindikasikan\n",
        "frekuensi kemunculan kata dlm dokumen tsb.\n",
        "\n",
        "kelemahan pd BoW ialah kehilangan informasi struktural dan urutan\n",
        "kata.'''"
      ],
      "metadata": {
        "id": "z2x9Ih-ZiCMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#an example code from copilot\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#document example\n",
        "documents = [\"Saya suka belajar machine learning\",\n",
        "            \"Machine learning sangat susah\",\n",
        "            \"Python pun sama saja\",\n",
        "            \"Tapi saya mau jadi Machine Learning Engineer\"]\n",
        "\n",
        "#inisialisasi CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "#fit dan transformasi dokumen\n",
        "bow_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "#menampilkan hasil bag of words\n",
        "print(\"fitur (kata-kata): \", vectorizer.get_feature_names_out())\n",
        "print(\"bag of words matrix:\\n\", bow_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HguaAa87k5zs",
        "outputId": "359d96bd-dcd7-4c47-c28f-721a64a9fa99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitur (kata-kata):  ['belajar' 'engineer' 'jadi' 'learning' 'machine' 'mau' 'pun' 'python'\n",
            " 'saja' 'sama' 'sangat' 'saya' 'suka' 'susah' 'tapi']\n",
            "bag of words matrix:\n",
            " [[1 0 0 1 1 0 0 0 0 0 0 1 1 0 0]\n",
            " [0 0 0 1 1 0 0 0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 1 1 0 0 0 0 0 1 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#N-gram\n",
        "'''\n",
        "sekumpulan n kata berurutan yg diambil dr sebuah teks atau urutan\n",
        "data. n-gram digunakan utk memahami hub antar kata dlm teks.\n",
        "cth umum n-gram yaitu unigram (1-gram), bigram (2-gram), dan trigram\n",
        "(3-gram).\n",
        "\n",
        "cth:\n",
        "uni-gram: this \\ is \\ a \\ sentence\n",
        "bi-gram: this is \\ is a \\ a sentence\n",
        "tri-gram: this is a \\ is a sentence"
      ],
      "metadata": {
        "id": "Dc4cKUmzmD2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}